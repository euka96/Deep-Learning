{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"연습문제2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMDh3L4ys8J7E4CUCmicdEf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fZUkI9cxRkmV"},"source":["## Taste of wine"]},{"cell_type":"code","metadata":{"id":"L-kkKDvXRIvz"},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","seed = 2021\n","np.random.seed(seed)\n","tf.random.set_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QhisBPxRMA7","executionInfo":{"status":"ok","timestamp":1624940059426,"user_tz":-540,"elapsed":2,"user":{"displayName":"Eugene Jeon","photoUrl":"","userId":"03040668084174208490"}},"outputId":"44e5af68-6ea8-49c8-a99e-c900585bb18c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opA8m8SKZODW","executionInfo":{"status":"ok","timestamp":1624940059810,"user_tz":-540,"elapsed":385,"user":{"displayName":"Eugene Jeon","photoUrl":"","userId":"03040668084174208490"}},"outputId":"c06c2e6c-1b87-4190-9954-cae3d3239081"},"source":["cd /content/drive/MyDrive/colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/colab\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"Bz2NWdmyRQJq","executionInfo":{"status":"ok","timestamp":1624940060186,"user_tz":-540,"elapsed":378,"user":{"displayName":"Eugene Jeon","photoUrl":"","userId":"03040668084174208490"}},"outputId":"bd994328-09a9-4f82-feb0-1d97ffeda902"},"source":["wine = pd.read_csv('dataset/wine.csv', header = None)\n","wine"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.99780</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.8</td>\n","      <td>0.88</td>\n","      <td>0.00</td>\n","      <td>2.6</td>\n","      <td>0.098</td>\n","      <td>25.0</td>\n","      <td>67.0</td>\n","      <td>0.99680</td>\n","      <td>3.20</td>\n","      <td>0.68</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.8</td>\n","      <td>0.76</td>\n","      <td>0.04</td>\n","      <td>2.3</td>\n","      <td>0.092</td>\n","      <td>15.0</td>\n","      <td>54.0</td>\n","      <td>0.99700</td>\n","      <td>3.26</td>\n","      <td>0.65</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.2</td>\n","      <td>0.28</td>\n","      <td>0.56</td>\n","      <td>1.9</td>\n","      <td>0.075</td>\n","      <td>17.0</td>\n","      <td>60.0</td>\n","      <td>0.99800</td>\n","      <td>3.16</td>\n","      <td>0.58</td>\n","      <td>9.8</td>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.99780</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6492</th>\n","      <td>6.2</td>\n","      <td>0.21</td>\n","      <td>0.29</td>\n","      <td>1.6</td>\n","      <td>0.039</td>\n","      <td>24.0</td>\n","      <td>92.0</td>\n","      <td>0.99114</td>\n","      <td>3.27</td>\n","      <td>0.50</td>\n","      <td>11.2</td>\n","      <td>6</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6493</th>\n","      <td>6.6</td>\n","      <td>0.32</td>\n","      <td>0.36</td>\n","      <td>8.0</td>\n","      <td>0.047</td>\n","      <td>57.0</td>\n","      <td>168.0</td>\n","      <td>0.99490</td>\n","      <td>3.15</td>\n","      <td>0.46</td>\n","      <td>9.6</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6494</th>\n","      <td>6.5</td>\n","      <td>0.24</td>\n","      <td>0.19</td>\n","      <td>1.2</td>\n","      <td>0.041</td>\n","      <td>30.0</td>\n","      <td>111.0</td>\n","      <td>0.99254</td>\n","      <td>2.99</td>\n","      <td>0.46</td>\n","      <td>9.4</td>\n","      <td>6</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6495</th>\n","      <td>5.5</td>\n","      <td>0.29</td>\n","      <td>0.30</td>\n","      <td>1.1</td>\n","      <td>0.022</td>\n","      <td>20.0</td>\n","      <td>110.0</td>\n","      <td>0.98869</td>\n","      <td>3.34</td>\n","      <td>0.38</td>\n","      <td>12.8</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6496</th>\n","      <td>6.0</td>\n","      <td>0.21</td>\n","      <td>0.38</td>\n","      <td>0.8</td>\n","      <td>0.020</td>\n","      <td>22.0</td>\n","      <td>98.0</td>\n","      <td>0.98941</td>\n","      <td>3.26</td>\n","      <td>0.32</td>\n","      <td>11.8</td>\n","      <td>6</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6497 rows × 13 columns</p>\n","</div>"],"text/plain":["        0     1     2    3      4     5   ...       7     8     9     10  11  12\n","0      7.4  0.70  0.00  1.9  0.076  11.0  ...  0.99780  3.51  0.56   9.4   5   1\n","1      7.8  0.88  0.00  2.6  0.098  25.0  ...  0.99680  3.20  0.68   9.8   5   1\n","2      7.8  0.76  0.04  2.3  0.092  15.0  ...  0.99700  3.26  0.65   9.8   5   1\n","3     11.2  0.28  0.56  1.9  0.075  17.0  ...  0.99800  3.16  0.58   9.8   6   1\n","4      7.4  0.70  0.00  1.9  0.076  11.0  ...  0.99780  3.51  0.56   9.4   5   1\n","...    ...   ...   ...  ...    ...   ...  ...      ...   ...   ...   ...  ..  ..\n","6492   6.2  0.21  0.29  1.6  0.039  24.0  ...  0.99114  3.27  0.50  11.2   6   0\n","6493   6.6  0.32  0.36  8.0  0.047  57.0  ...  0.99490  3.15  0.46   9.6   5   0\n","6494   6.5  0.24  0.19  1.2  0.041  30.0  ...  0.99254  2.99  0.46   9.4   6   0\n","6495   5.5  0.29  0.30  1.1  0.022  20.0  ...  0.98869  3.34  0.38  12.8   7   0\n","6496   6.0  0.21  0.38  0.8  0.020  22.0  ...  0.98941  3.26  0.32  11.8   6   0\n","\n","[6497 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":200}]},{"cell_type":"markdown","metadata":{"id":"XpHIueacRgUl"},"source":["### Preprocessing"]},{"cell_type":"code","metadata":{"id":"1qwHA_JDk6mP"},"source":["wine = wine[wine[11] != 3]\n","wine = wine[wine[11] != 9]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ziww6qMjozyw"},"source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(wine.iloc[:,: -2].values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZI4T0N1hks7p","executionInfo":{"status":"ok","timestamp":1624940063796,"user_tz":-540,"elapsed":2,"user":{"displayName":"Eugene Jeon","photoUrl":"","userId":"03040668084174208490"}},"outputId":"e7f0924c-3b5e-4519-a527-0d265a348967"},"source":["from tensorflow.keras.utils import to_categorical\n","\n","y = to_categorical(wine.iloc[:, -2].values)\n","y"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 1., 0., 0.],\n","       [0., 0., 0., ..., 0., 1., 0.],\n","       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":203}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nz953tU7Sdnu","executionInfo":{"status":"ok","timestamp":1624940063797,"user_tz":-540,"elapsed":3,"user":{"displayName":"Eugene Jeon","photoUrl":"","userId":"03040668084174208490"}},"outputId":"eee7b45a-7d79-4473-f02e-73af6e9f515e"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(\n","    X_scaled, y, stratify = y, random_state = seed\n",")\n","\n","X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4846, 11), (1616, 11), (4846, 9), (1616, 9))"]},"metadata":{"tags":[]},"execution_count":204}]},{"cell_type":"markdown","metadata":{"id":"cMrIdIpmS5uD"},"source":["### Processing"]},{"cell_type":"code","metadata":{"id":"8RXCkRt_S4IY"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4braVC4aTBiO","executionInfo":{"status":"ok","timestamp":1624940064525,"user_tz":-540,"elapsed":2,"user":{"displayName":"Eugene Jeon","photoUrl":"","userId":"03040668084174208490"}},"outputId":"ca1173d3-eb90-4a5a-bd8e-6a1a16797811"},"source":["model = Sequential()\n","model.add(Dense(30, input_dim = 11, activation = 'relu'))\n","model.add(Dense(20, activation = 'relu'))\n","model.add(Dense(15, activation = 'relu'))\n","model.add(Dense(9, activation = 'softmax'))\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_15\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_60 (Dense)             (None, 30)                360       \n","_________________________________________________________________\n","dense_61 (Dense)             (None, 20)                620       \n","_________________________________________________________________\n","dense_62 (Dense)             (None, 15)                315       \n","_________________________________________________________________\n","dense_63 (Dense)             (None, 9)                 144       \n","=================================================================\n","Total params: 1,439\n","Trainable params: 1,439\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xP-7K8bqTaSy"},"source":["model.compile(\n","    optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T7AXYfuTZCGe"},"source":["#### Setting for saving model"]},{"cell_type":"code","metadata":{"id":"0oCN15OAZHv5"},"source":["modelpath = '1. Basic Model/Models/best_taste.h5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QIoNV5FSZpTy"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","checkpointer = ModelCheckpoint(\n","    modelpath, monitor = 'val_loss', verbose = 1, save_best_only = True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7F1hvMw1euQl"},"source":["from tensorflow.keras.callbacks import EarlyStopping\n","early_stopping = EarlyStopping(patience = 50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMjFgewhaKjS"},"source":["#### Learing and saving model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vHUzw2Sjnukr","executionInfo":{"status":"ok","timestamp":1624940095561,"user_tz":-540,"elapsed":29986,"user":{"displayName":"Eugene Jeon","photoUrl":"","userId":"03040668084174208490"}},"outputId":"ecbb5f40-6c55-4a8d-a430-49737a6d15f6"},"source":["history = model.fit(\n","    X_train, Y_train, validation_split = 0.2,\n","    epochs = 1000, batch_size = 200, verbose = 0, callbacks = [checkpointer, early_stopping]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 2.14117, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00002: val_loss improved from 2.14117 to 2.04210, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00003: val_loss improved from 2.04210 to 1.86803, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00004: val_loss improved from 1.86803 to 1.66731, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00005: val_loss improved from 1.66731 to 1.47241, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00006: val_loss improved from 1.47241 to 1.32135, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00007: val_loss improved from 1.32135 to 1.25583, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00008: val_loss improved from 1.25583 to 1.21456, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00009: val_loss improved from 1.21456 to 1.18148, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00010: val_loss improved from 1.18148 to 1.15548, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00011: val_loss improved from 1.15548 to 1.13601, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00012: val_loss improved from 1.13601 to 1.11286, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00013: val_loss improved from 1.11286 to 1.09943, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00014: val_loss improved from 1.09943 to 1.09269, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00015: val_loss improved from 1.09269 to 1.08097, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00016: val_loss improved from 1.08097 to 1.07579, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00017: val_loss improved from 1.07579 to 1.06719, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00018: val_loss improved from 1.06719 to 1.06345, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00019: val_loss improved from 1.06345 to 1.06112, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00020: val_loss improved from 1.06112 to 1.05620, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00021: val_loss did not improve from 1.05620\n","\n","Epoch 00022: val_loss improved from 1.05620 to 1.05496, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00023: val_loss did not improve from 1.05496\n","\n","Epoch 00024: val_loss improved from 1.05496 to 1.05197, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00025: val_loss improved from 1.05197 to 1.04950, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00026: val_loss did not improve from 1.04950\n","\n","Epoch 00027: val_loss did not improve from 1.04950\n","\n","Epoch 00028: val_loss improved from 1.04950 to 1.04841, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00029: val_loss did not improve from 1.04841\n","\n","Epoch 00030: val_loss improved from 1.04841 to 1.04609, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00031: val_loss improved from 1.04609 to 1.04579, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00032: val_loss did not improve from 1.04579\n","\n","Epoch 00033: val_loss did not improve from 1.04579\n","\n","Epoch 00034: val_loss improved from 1.04579 to 1.04514, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00035: val_loss improved from 1.04514 to 1.04395, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00036: val_loss did not improve from 1.04395\n","\n","Epoch 00037: val_loss did not improve from 1.04395\n","\n","Epoch 00038: val_loss improved from 1.04395 to 1.04349, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00039: val_loss did not improve from 1.04349\n","\n","Epoch 00040: val_loss did not improve from 1.04349\n","\n","Epoch 00041: val_loss improved from 1.04349 to 1.04041, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00042: val_loss improved from 1.04041 to 1.03880, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00043: val_loss did not improve from 1.03880\n","\n","Epoch 00044: val_loss did not improve from 1.03880\n","\n","Epoch 00045: val_loss improved from 1.03880 to 1.03570, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00046: val_loss did not improve from 1.03570\n","\n","Epoch 00047: val_loss improved from 1.03570 to 1.03377, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00048: val_loss improved from 1.03377 to 1.03298, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00049: val_loss improved from 1.03298 to 1.03220, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00050: val_loss did not improve from 1.03220\n","\n","Epoch 00051: val_loss did not improve from 1.03220\n","\n","Epoch 00052: val_loss did not improve from 1.03220\n","\n","Epoch 00053: val_loss improved from 1.03220 to 1.03066, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00054: val_loss did not improve from 1.03066\n","\n","Epoch 00055: val_loss did not improve from 1.03066\n","\n","Epoch 00056: val_loss did not improve from 1.03066\n","\n","Epoch 00057: val_loss improved from 1.03066 to 1.02962, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00058: val_loss did not improve from 1.02962\n","\n","Epoch 00059: val_loss improved from 1.02962 to 1.02708, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00060: val_loss improved from 1.02708 to 1.02452, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00061: val_loss did not improve from 1.02452\n","\n","Epoch 00062: val_loss did not improve from 1.02452\n","\n","Epoch 00063: val_loss did not improve from 1.02452\n","\n","Epoch 00064: val_loss improved from 1.02452 to 1.02362, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00065: val_loss did not improve from 1.02362\n","\n","Epoch 00066: val_loss did not improve from 1.02362\n","\n","Epoch 00067: val_loss did not improve from 1.02362\n","\n","Epoch 00068: val_loss did not improve from 1.02362\n","\n","Epoch 00069: val_loss improved from 1.02362 to 1.02011, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00070: val_loss improved from 1.02011 to 1.01998, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00071: val_loss improved from 1.01998 to 1.01947, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00072: val_loss did not improve from 1.01947\n","\n","Epoch 00073: val_loss improved from 1.01947 to 1.01802, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00074: val_loss did not improve from 1.01802\n","\n","Epoch 00075: val_loss improved from 1.01802 to 1.01581, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00076: val_loss did not improve from 1.01581\n","\n","Epoch 00077: val_loss did not improve from 1.01581\n","\n","Epoch 00078: val_loss did not improve from 1.01581\n","\n","Epoch 00079: val_loss did not improve from 1.01581\n","\n","Epoch 00080: val_loss improved from 1.01581 to 1.01396, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00081: val_loss did not improve from 1.01396\n","\n","Epoch 00082: val_loss did not improve from 1.01396\n","\n","Epoch 00083: val_loss did not improve from 1.01396\n","\n","Epoch 00084: val_loss did not improve from 1.01396\n","\n","Epoch 00085: val_loss did not improve from 1.01396\n","\n","Epoch 00086: val_loss improved from 1.01396 to 1.01362, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00087: val_loss did not improve from 1.01362\n","\n","Epoch 00088: val_loss improved from 1.01362 to 1.01154, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00089: val_loss did not improve from 1.01154\n","\n","Epoch 00090: val_loss did not improve from 1.01154\n","\n","Epoch 00091: val_loss did not improve from 1.01154\n","\n","Epoch 00092: val_loss did not improve from 1.01154\n","\n","Epoch 00093: val_loss did not improve from 1.01154\n","\n","Epoch 00094: val_loss did not improve from 1.01154\n","\n","Epoch 00095: val_loss did not improve from 1.01154\n","\n","Epoch 00096: val_loss did not improve from 1.01154\n","\n","Epoch 00097: val_loss did not improve from 1.01154\n","\n","Epoch 00098: val_loss improved from 1.01154 to 1.01047, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00099: val_loss did not improve from 1.01047\n","\n","Epoch 00100: val_loss did not improve from 1.01047\n","\n","Epoch 00101: val_loss did not improve from 1.01047\n","\n","Epoch 00102: val_loss did not improve from 1.01047\n","\n","Epoch 00103: val_loss improved from 1.01047 to 1.00988, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00104: val_loss did not improve from 1.00988\n","\n","Epoch 00105: val_loss did not improve from 1.00988\n","\n","Epoch 00106: val_loss did not improve from 1.00988\n","\n","Epoch 00107: val_loss improved from 1.00988 to 1.00824, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00108: val_loss did not improve from 1.00824\n","\n","Epoch 00109: val_loss did not improve from 1.00824\n","\n","Epoch 00110: val_loss did not improve from 1.00824\n","\n","Epoch 00111: val_loss did not improve from 1.00824\n","\n","Epoch 00112: val_loss did not improve from 1.00824\n","\n","Epoch 00113: val_loss did not improve from 1.00824\n","\n","Epoch 00114: val_loss improved from 1.00824 to 1.00735, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00115: val_loss did not improve from 1.00735\n","\n","Epoch 00116: val_loss did not improve from 1.00735\n","\n","Epoch 00117: val_loss did not improve from 1.00735\n","\n","Epoch 00118: val_loss did not improve from 1.00735\n","\n","Epoch 00119: val_loss did not improve from 1.00735\n","\n","Epoch 00120: val_loss did not improve from 1.00735\n","\n","Epoch 00121: val_loss did not improve from 1.00735\n","\n","Epoch 00122: val_loss did not improve from 1.00735\n","\n","Epoch 00123: val_loss improved from 1.00735 to 1.00722, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00124: val_loss did not improve from 1.00722\n","\n","Epoch 00125: val_loss did not improve from 1.00722\n","\n","Epoch 00126: val_loss did not improve from 1.00722\n","\n","Epoch 00127: val_loss improved from 1.00722 to 1.00686, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00128: val_loss did not improve from 1.00686\n","\n","Epoch 00129: val_loss did not improve from 1.00686\n","\n","Epoch 00130: val_loss improved from 1.00686 to 1.00476, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00131: val_loss did not improve from 1.00476\n","\n","Epoch 00132: val_loss did not improve from 1.00476\n","\n","Epoch 00133: val_loss did not improve from 1.00476\n","\n","Epoch 00134: val_loss did not improve from 1.00476\n","\n","Epoch 00135: val_loss did not improve from 1.00476\n","\n","Epoch 00136: val_loss did not improve from 1.00476\n","\n","Epoch 00137: val_loss improved from 1.00476 to 1.00425, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00138: val_loss did not improve from 1.00425\n","\n","Epoch 00139: val_loss did not improve from 1.00425\n","\n","Epoch 00140: val_loss did not improve from 1.00425\n","\n","Epoch 00141: val_loss did not improve from 1.00425\n","\n","Epoch 00142: val_loss improved from 1.00425 to 1.00374, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00143: val_loss did not improve from 1.00374\n","\n","Epoch 00144: val_loss did not improve from 1.00374\n","\n","Epoch 00145: val_loss did not improve from 1.00374\n","\n","Epoch 00146: val_loss did not improve from 1.00374\n","\n","Epoch 00147: val_loss did not improve from 1.00374\n","\n","Epoch 00148: val_loss improved from 1.00374 to 1.00314, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00149: val_loss did not improve from 1.00314\n","\n","Epoch 00150: val_loss did not improve from 1.00314\n","\n","Epoch 00151: val_loss did not improve from 1.00314\n","\n","Epoch 00152: val_loss did not improve from 1.00314\n","\n","Epoch 00153: val_loss did not improve from 1.00314\n","\n","Epoch 00154: val_loss improved from 1.00314 to 1.00294, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00155: val_loss did not improve from 1.00294\n","\n","Epoch 00156: val_loss improved from 1.00294 to 1.00171, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00157: val_loss improved from 1.00171 to 1.00148, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00158: val_loss did not improve from 1.00148\n","\n","Epoch 00159: val_loss did not improve from 1.00148\n","\n","Epoch 00160: val_loss did not improve from 1.00148\n","\n","Epoch 00161: val_loss did not improve from 1.00148\n","\n","Epoch 00162: val_loss did not improve from 1.00148\n","\n","Epoch 00163: val_loss did not improve from 1.00148\n","\n","Epoch 00164: val_loss improved from 1.00148 to 1.00008, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00165: val_loss did not improve from 1.00008\n","\n","Epoch 00166: val_loss did not improve from 1.00008\n","\n","Epoch 00167: val_loss did not improve from 1.00008\n","\n","Epoch 00168: val_loss did not improve from 1.00008\n","\n","Epoch 00169: val_loss did not improve from 1.00008\n","\n","Epoch 00170: val_loss improved from 1.00008 to 0.99833, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00171: val_loss did not improve from 0.99833\n","\n","Epoch 00172: val_loss did not improve from 0.99833\n","\n","Epoch 00173: val_loss improved from 0.99833 to 0.99677, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00174: val_loss improved from 0.99677 to 0.99508, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00175: val_loss did not improve from 0.99508\n","\n","Epoch 00176: val_loss improved from 0.99508 to 0.99480, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00177: val_loss did not improve from 0.99480\n","\n","Epoch 00178: val_loss did not improve from 0.99480\n","\n","Epoch 00179: val_loss did not improve from 0.99480\n","\n","Epoch 00180: val_loss improved from 0.99480 to 0.99379, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00181: val_loss did not improve from 0.99379\n","\n","Epoch 00182: val_loss did not improve from 0.99379\n","\n","Epoch 00183: val_loss did not improve from 0.99379\n","\n","Epoch 00184: val_loss improved from 0.99379 to 0.99349, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00185: val_loss did not improve from 0.99349\n","\n","Epoch 00186: val_loss did not improve from 0.99349\n","\n","Epoch 00187: val_loss did not improve from 0.99349\n","\n","Epoch 00188: val_loss did not improve from 0.99349\n","\n","Epoch 00189: val_loss did not improve from 0.99349\n","\n","Epoch 00190: val_loss improved from 0.99349 to 0.99154, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00191: val_loss did not improve from 0.99154\n","\n","Epoch 00192: val_loss did not improve from 0.99154\n","\n","Epoch 00193: val_loss did not improve from 0.99154\n","\n","Epoch 00194: val_loss improved from 0.99154 to 0.99067, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00195: val_loss did not improve from 0.99067\n","\n","Epoch 00196: val_loss did not improve from 0.99067\n","\n","Epoch 00197: val_loss did not improve from 0.99067\n","\n","Epoch 00198: val_loss did not improve from 0.99067\n","\n","Epoch 00199: val_loss did not improve from 0.99067\n","\n","Epoch 00200: val_loss did not improve from 0.99067\n","\n","Epoch 00201: val_loss did not improve from 0.99067\n","\n","Epoch 00202: val_loss did not improve from 0.99067\n","\n","Epoch 00203: val_loss did not improve from 0.99067\n","\n","Epoch 00204: val_loss did not improve from 0.99067\n","\n","Epoch 00205: val_loss did not improve from 0.99067\n","\n","Epoch 00206: val_loss did not improve from 0.99067\n","\n","Epoch 00207: val_loss did not improve from 0.99067\n","\n","Epoch 00208: val_loss improved from 0.99067 to 0.99015, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00209: val_loss did not improve from 0.99015\n","\n","Epoch 00210: val_loss did not improve from 0.99015\n","\n","Epoch 00211: val_loss did not improve from 0.99015\n","\n","Epoch 00212: val_loss did not improve from 0.99015\n","\n","Epoch 00213: val_loss did not improve from 0.99015\n","\n","Epoch 00214: val_loss did not improve from 0.99015\n","\n","Epoch 00215: val_loss did not improve from 0.99015\n","\n","Epoch 00216: val_loss did not improve from 0.99015\n","\n","Epoch 00217: val_loss did not improve from 0.99015\n","\n","Epoch 00218: val_loss did not improve from 0.99015\n","\n","Epoch 00219: val_loss did not improve from 0.99015\n","\n","Epoch 00220: val_loss did not improve from 0.99015\n","\n","Epoch 00221: val_loss did not improve from 0.99015\n","\n","Epoch 00222: val_loss improved from 0.99015 to 0.99014, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00223: val_loss did not improve from 0.99014\n","\n","Epoch 00224: val_loss did not improve from 0.99014\n","\n","Epoch 00225: val_loss did not improve from 0.99014\n","\n","Epoch 00226: val_loss did not improve from 0.99014\n","\n","Epoch 00227: val_loss did not improve from 0.99014\n","\n","Epoch 00228: val_loss did not improve from 0.99014\n","\n","Epoch 00229: val_loss did not improve from 0.99014\n","\n","Epoch 00230: val_loss did not improve from 0.99014\n","\n","Epoch 00231: val_loss improved from 0.99014 to 0.98979, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00232: val_loss did not improve from 0.98979\n","\n","Epoch 00233: val_loss did not improve from 0.98979\n","\n","Epoch 00234: val_loss improved from 0.98979 to 0.98868, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00235: val_loss did not improve from 0.98868\n","\n","Epoch 00236: val_loss did not improve from 0.98868\n","\n","Epoch 00237: val_loss did not improve from 0.98868\n","\n","Epoch 00238: val_loss did not improve from 0.98868\n","\n","Epoch 00239: val_loss did not improve from 0.98868\n","\n","Epoch 00240: val_loss did not improve from 0.98868\n","\n","Epoch 00241: val_loss did not improve from 0.98868\n","\n","Epoch 00242: val_loss did not improve from 0.98868\n","\n","Epoch 00243: val_loss improved from 0.98868 to 0.98820, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00244: val_loss did not improve from 0.98820\n","\n","Epoch 00245: val_loss did not improve from 0.98820\n","\n","Epoch 00246: val_loss did not improve from 0.98820\n","\n","Epoch 00247: val_loss did not improve from 0.98820\n","\n","Epoch 00248: val_loss did not improve from 0.98820\n","\n","Epoch 00249: val_loss improved from 0.98820 to 0.98733, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00250: val_loss did not improve from 0.98733\n","\n","Epoch 00251: val_loss did not improve from 0.98733\n","\n","Epoch 00252: val_loss did not improve from 0.98733\n","\n","Epoch 00253: val_loss did not improve from 0.98733\n","\n","Epoch 00254: val_loss did not improve from 0.98733\n","\n","Epoch 00255: val_loss did not improve from 0.98733\n","\n","Epoch 00256: val_loss did not improve from 0.98733\n","\n","Epoch 00257: val_loss did not improve from 0.98733\n","\n","Epoch 00258: val_loss improved from 0.98733 to 0.98688, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00259: val_loss did not improve from 0.98688\n","\n","Epoch 00260: val_loss did not improve from 0.98688\n","\n","Epoch 00261: val_loss did not improve from 0.98688\n","\n","Epoch 00262: val_loss did not improve from 0.98688\n","\n","Epoch 00263: val_loss did not improve from 0.98688\n","\n","Epoch 00264: val_loss did not improve from 0.98688\n","\n","Epoch 00265: val_loss did not improve from 0.98688\n","\n","Epoch 00266: val_loss did not improve from 0.98688\n","\n","Epoch 00267: val_loss did not improve from 0.98688\n","\n","Epoch 00268: val_loss did not improve from 0.98688\n","\n","Epoch 00269: val_loss did not improve from 0.98688\n","\n","Epoch 00270: val_loss did not improve from 0.98688\n","\n","Epoch 00271: val_loss improved from 0.98688 to 0.98682, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00272: val_loss did not improve from 0.98682\n","\n","Epoch 00273: val_loss did not improve from 0.98682\n","\n","Epoch 00274: val_loss did not improve from 0.98682\n","\n","Epoch 00275: val_loss did not improve from 0.98682\n","\n","Epoch 00276: val_loss did not improve from 0.98682\n","\n","Epoch 00277: val_loss did not improve from 0.98682\n","\n","Epoch 00278: val_loss did not improve from 0.98682\n","\n","Epoch 00279: val_loss did not improve from 0.98682\n","\n","Epoch 00280: val_loss did not improve from 0.98682\n","\n","Epoch 00281: val_loss did not improve from 0.98682\n","\n","Epoch 00282: val_loss improved from 0.98682 to 0.98652, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00283: val_loss did not improve from 0.98652\n","\n","Epoch 00284: val_loss did not improve from 0.98652\n","\n","Epoch 00285: val_loss improved from 0.98652 to 0.98613, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00286: val_loss did not improve from 0.98613\n","\n","Epoch 00287: val_loss did not improve from 0.98613\n","\n","Epoch 00288: val_loss did not improve from 0.98613\n","\n","Epoch 00289: val_loss did not improve from 0.98613\n","\n","Epoch 00290: val_loss did not improve from 0.98613\n","\n","Epoch 00291: val_loss did not improve from 0.98613\n","\n","Epoch 00292: val_loss did not improve from 0.98613\n","\n","Epoch 00293: val_loss did not improve from 0.98613\n","\n","Epoch 00294: val_loss did not improve from 0.98613\n","\n","Epoch 00295: val_loss improved from 0.98613 to 0.98509, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00296: val_loss did not improve from 0.98509\n","\n","Epoch 00297: val_loss did not improve from 0.98509\n","\n","Epoch 00298: val_loss did not improve from 0.98509\n","\n","Epoch 00299: val_loss did not improve from 0.98509\n","\n","Epoch 00300: val_loss did not improve from 0.98509\n","\n","Epoch 00301: val_loss did not improve from 0.98509\n","\n","Epoch 00302: val_loss did not improve from 0.98509\n","\n","Epoch 00303: val_loss did not improve from 0.98509\n","\n","Epoch 00304: val_loss did not improve from 0.98509\n","\n","Epoch 00305: val_loss did not improve from 0.98509\n","\n","Epoch 00306: val_loss improved from 0.98509 to 0.98487, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00307: val_loss did not improve from 0.98487\n","\n","Epoch 00308: val_loss did not improve from 0.98487\n","\n","Epoch 00309: val_loss did not improve from 0.98487\n","\n","Epoch 00310: val_loss did not improve from 0.98487\n","\n","Epoch 00311: val_loss did not improve from 0.98487\n","\n","Epoch 00312: val_loss did not improve from 0.98487\n","\n","Epoch 00313: val_loss did not improve from 0.98487\n","\n","Epoch 00314: val_loss did not improve from 0.98487\n","\n","Epoch 00315: val_loss did not improve from 0.98487\n","\n","Epoch 00316: val_loss did not improve from 0.98487\n","\n","Epoch 00317: val_loss did not improve from 0.98487\n","\n","Epoch 00318: val_loss did not improve from 0.98487\n","\n","Epoch 00319: val_loss did not improve from 0.98487\n","\n","Epoch 00320: val_loss did not improve from 0.98487\n","\n","Epoch 00321: val_loss did not improve from 0.98487\n","\n","Epoch 00322: val_loss did not improve from 0.98487\n","\n","Epoch 00323: val_loss improved from 0.98487 to 0.98458, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00324: val_loss did not improve from 0.98458\n","\n","Epoch 00325: val_loss did not improve from 0.98458\n","\n","Epoch 00326: val_loss did not improve from 0.98458\n","\n","Epoch 00327: val_loss did not improve from 0.98458\n","\n","Epoch 00328: val_loss did not improve from 0.98458\n","\n","Epoch 00329: val_loss did not improve from 0.98458\n","\n","Epoch 00330: val_loss did not improve from 0.98458\n","\n","Epoch 00331: val_loss did not improve from 0.98458\n","\n","Epoch 00332: val_loss did not improve from 0.98458\n","\n","Epoch 00333: val_loss did not improve from 0.98458\n","\n","Epoch 00334: val_loss did not improve from 0.98458\n","\n","Epoch 00335: val_loss did not improve from 0.98458\n","\n","Epoch 00336: val_loss improved from 0.98458 to 0.98429, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00337: val_loss did not improve from 0.98429\n","\n","Epoch 00338: val_loss did not improve from 0.98429\n","\n","Epoch 00339: val_loss did not improve from 0.98429\n","\n","Epoch 00340: val_loss did not improve from 0.98429\n","\n","Epoch 00341: val_loss did not improve from 0.98429\n","\n","Epoch 00342: val_loss did not improve from 0.98429\n","\n","Epoch 00343: val_loss did not improve from 0.98429\n","\n","Epoch 00344: val_loss did not improve from 0.98429\n","\n","Epoch 00345: val_loss did not improve from 0.98429\n","\n","Epoch 00346: val_loss did not improve from 0.98429\n","\n","Epoch 00347: val_loss did not improve from 0.98429\n","\n","Epoch 00348: val_loss did not improve from 0.98429\n","\n","Epoch 00349: val_loss did not improve from 0.98429\n","\n","Epoch 00350: val_loss did not improve from 0.98429\n","\n","Epoch 00351: val_loss did not improve from 0.98429\n","\n","Epoch 00352: val_loss did not improve from 0.98429\n","\n","Epoch 00353: val_loss did not improve from 0.98429\n","\n","Epoch 00354: val_loss did not improve from 0.98429\n","\n","Epoch 00355: val_loss did not improve from 0.98429\n","\n","Epoch 00356: val_loss did not improve from 0.98429\n","\n","Epoch 00357: val_loss did not improve from 0.98429\n","\n","Epoch 00358: val_loss improved from 0.98429 to 0.98392, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00359: val_loss improved from 0.98392 to 0.98359, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00360: val_loss did not improve from 0.98359\n","\n","Epoch 00361: val_loss did not improve from 0.98359\n","\n","Epoch 00362: val_loss did not improve from 0.98359\n","\n","Epoch 00363: val_loss improved from 0.98359 to 0.98319, saving model to 1. Basic Model/Models/best_taste.h5\n","\n","Epoch 00364: val_loss did not improve from 0.98319\n","\n","Epoch 00365: val_loss did not improve from 0.98319\n","\n","Epoch 00366: val_loss did not improve from 0.98319\n","\n","Epoch 00367: val_loss did not improve from 0.98319\n","\n","Epoch 00368: val_loss did not improve from 0.98319\n","\n","Epoch 00369: val_loss did not improve from 0.98319\n","\n","Epoch 00370: val_loss did not improve from 0.98319\n","\n","Epoch 00371: val_loss did not improve from 0.98319\n","\n","Epoch 00372: val_loss did not improve from 0.98319\n","\n","Epoch 00373: val_loss did not improve from 0.98319\n","\n","Epoch 00374: val_loss did not improve from 0.98319\n","\n","Epoch 00375: val_loss did not improve from 0.98319\n","\n","Epoch 00376: val_loss did not improve from 0.98319\n","\n","Epoch 00377: val_loss did not improve from 0.98319\n","\n","Epoch 00378: val_loss did not improve from 0.98319\n","\n","Epoch 00379: val_loss did not improve from 0.98319\n","\n","Epoch 00380: val_loss did not improve from 0.98319\n","\n","Epoch 00381: val_loss did not improve from 0.98319\n","\n","Epoch 00382: val_loss did not improve from 0.98319\n","\n","Epoch 00383: val_loss did not improve from 0.98319\n","\n","Epoch 00384: val_loss did not improve from 0.98319\n","\n","Epoch 00385: val_loss did not improve from 0.98319\n","\n","Epoch 00386: val_loss did not improve from 0.98319\n","\n","Epoch 00387: val_loss did not improve from 0.98319\n","\n","Epoch 00388: val_loss did not improve from 0.98319\n","\n","Epoch 00389: val_loss did not improve from 0.98319\n","\n","Epoch 00390: val_loss did not improve from 0.98319\n","\n","Epoch 00391: val_loss did not improve from 0.98319\n","\n","Epoch 00392: val_loss did not improve from 0.98319\n","\n","Epoch 00393: val_loss did not improve from 0.98319\n","\n","Epoch 00394: val_loss did not improve from 0.98319\n","\n","Epoch 00395: val_loss did not improve from 0.98319\n","\n","Epoch 00396: val_loss did not improve from 0.98319\n","\n","Epoch 00397: val_loss did not improve from 0.98319\n","\n","Epoch 00398: val_loss did not improve from 0.98319\n","\n","Epoch 00399: val_loss did not improve from 0.98319\n","\n","Epoch 00400: val_loss did not improve from 0.98319\n","\n","Epoch 00401: val_loss did not improve from 0.98319\n","\n","Epoch 00402: val_loss did not improve from 0.98319\n","\n","Epoch 00403: val_loss did not improve from 0.98319\n","\n","Epoch 00404: val_loss did not improve from 0.98319\n","\n","Epoch 00405: val_loss did not improve from 0.98319\n","\n","Epoch 00406: val_loss did not improve from 0.98319\n","\n","Epoch 00407: val_loss did not improve from 0.98319\n","\n","Epoch 00408: val_loss did not improve from 0.98319\n","\n","Epoch 00409: val_loss did not improve from 0.98319\n","\n","Epoch 00410: val_loss did not improve from 0.98319\n","\n","Epoch 00411: val_loss did not improve from 0.98319\n","\n","Epoch 00412: val_loss did not improve from 0.98319\n","\n","Epoch 00413: val_loss did not improve from 0.98319\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lj9nYU_bbgNV"},"source":["#### Evaluating with the best model"]},{"cell_type":"code","metadata":{"id":"BZKKPhcST4jS"},"source":["from tensorflow.keras.models import load_model\n","best_model = load_model('1. Basic Model/Models/best_taste.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnET0d_tbwvl","executionInfo":{"status":"ok","timestamp":1624940107463,"user_tz":-540,"elapsed":10,"user":{"displayName":"Eugene Jeon","photoUrl":"","userId":"03040668084174208490"}},"outputId":"78c9fb1b-9c3a-4ef6-e38b-4495eefe0a3e"},"source":["best_model.evaluate(X_test, Y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["51/51 [==============================] - 0s 1ms/step - loss: 1.0242 - accuracy: 0.5501\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.0242393016815186, 0.5501237511634827]"]},"metadata":{"tags":[]},"execution_count":213}]}]}